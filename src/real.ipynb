{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.utils.plotting import Annotator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to draw a traffic light\n",
    "def draw_traffic_light(img, state):\n",
    "    rect_x, rect_y = 725, 42 # Position of the rectangle\n",
    "    rect_width, rect_height = 150, 420 # Size of the rectangle\n",
    "    border_radius = 20 # Radius of rounded borders\n",
    "    rectangle_color = (169, 169, 169) # Color of the rectangle\n",
    "    cv2.rectangle(img, (rect_x, rect_y), (rect_x + rect_width, rect_y + rect_height), rectangle_color, -1)\n",
    "    cv2.rectangle(img, (rect_x, rect_y), (rect_x + rect_width, rect_y + rect_height), (169, 169, 169), 3, cv2.LINE_AA)\n",
    "    cv2.rectangle(img, (rect_x + border_radius, rect_y), (rect_x + rect_width - border_radius, rect_y + rect_height), (169, 169, 169), -1)\n",
    "    cv2.rectangle(img, (rect_x, rect_y + border_radius), (rect_x + rect_width, rect_y + rect_height - border_radius), (169, 169, 169), -1)\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText(img,f\"State: {state}\", (713, 500),font, 1, (0, 0, 0), 2, cv2.LINE_AA)\n",
    "    # Change state\n",
    "    if state == 'red':\n",
    "        cv2.circle(img, (800, 100), 50, (0, 0, 255), -1)\n",
    "        cv2.circle(img, (800, 250), 50, (0, 0, 0), -1)\n",
    "        cv2.circle(img, (800, 400), 50, (0, 0, 0), -1)\n",
    "    elif state == 'yellow':\n",
    "        cv2.circle(img, (800, 250), 50, (0, 255, 255), -1)\n",
    "        cv2.circle(img, (800, 100), 50, (0, 0, 0), -1)\n",
    "        cv2.circle(img, (800, 400), 50, (0, 0, 0), -1)\n",
    "    elif state == 'green':\n",
    "        cv2.circle(img, (800, 400), 50, (0, 255, 0), -1)\n",
    "        cv2.circle(img, (800, 250), 50, (0, 0, 0), -1)\n",
    "        cv2.circle(img, (800, 100), 50, (0, 0, 0), -1)\n",
    "\n",
    "# Function to draw digital timer\n",
    "def draw_timer(img, seconds):\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText(img, f\"Time: {seconds}\", (20, 480), font, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    \n",
    "def light(light_state,distance,distance_2,moved_from_eye1,moved_from_eye2):\n",
    "    if distance <= 1 and not moved_from_eye1 and moved_from_eye2: # Moving in radius of 1 vision eye.\n",
    "        light_state = 'yellow'\n",
    "    elif distance_2 <= 1 and moved_from_eye1 and not moved_from_eye2: # Moving in radius of 2 vision eye.\n",
    "        light_state = 'yellow'\n",
    "    elif distance_2 <= 1 and not moved_from_eye1 and moved_from_eye2: # Moving out of radius of 1 vision eye.\n",
    "        light_state = 'yellow'\n",
    "    elif distance_2 <= 1 and not moved_from_eye1 and moved_from_eye2: # Moving out of radius of 2 vision eye.\n",
    "        light_state = 'yellow'\n",
    "    elif not moved_from_eye1 and moved_from_eye2: # Moving towards 1 vision eye.\n",
    "        light_state = 'red'\n",
    "    elif moved_from_eye1 and not moved_from_eye2: # Moving towards 2 vision eye.\n",
    "        light_state = 'red'\n",
    "    else:\n",
    "        light_state = 'green'\n",
    "    return light_state\n",
    "        \n",
    "def direction(moved_from_eye1,moved_from_eye2): \n",
    "    if(moved_from_eye1 and moved_from_eye2):\n",
    "        print(f\"Object is moving away from crosswalk\")\n",
    "    elif(moved_from_eye1 and not moved_from_eye2):\n",
    "        print(f\"Object is moving towards right end of crosswalk\")\n",
    "    elif(not moved_from_eye1 and  moved_from_eye2):\n",
    "        print(f\"Object is moving towards left end of crosswalk\")\n",
    "    else:\n",
    "        print(f\"Object is moving towards crosswalk\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function\n",
    "def main():\n",
    "    cap = cv2.VideoCapture(\"vid1.mp4\")\n",
    "    w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
    "    out = cv2.VideoWriter('visioneye-distance-calculation.avi', cv2.VideoWriter_fourcc(*'MJPG'), fps, (w, h))\n",
    "    pixel_per_meter = 70\n",
    "    txt_color, txt_background, bbox_clr = ((0, 0, 0), (255, 255, 255), (255, 0, 255))\n",
    "    txt_color_2, txt_background_2, bbox_clr_2 = ((119, 7, 55), (255, 182, 193), (255, 0, 255))\n",
    "    # Video capture\n",
    "    cap = cv2.VideoCapture('vid1.mp4') # Replace 'your_video.mp4' with your video file\n",
    "\n",
    "    # Dictionary to store tracking IDs and coordinates\n",
    "    prev_coordinates = {}\n",
    "    distance = 0\n",
    "    distance_2 = 0    \n",
    "    \n",
    "    # Traffic light state\n",
    "    light_state = 'green'\n",
    "    \n",
    "    # Timer\n",
    "    start_time = time.time()\n",
    "    elapsed_time = 0\n",
    "    height = 500\n",
    "    width = 1000\n",
    "    moved_from_eye1 = False\n",
    "    moved_from_eye2 = False\n",
    "\n",
    "    while True:\n",
    "        ret, im0 = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Video frame is empty or video processing has been successfully completed.\")\n",
    "            break\n",
    "        \n",
    "        # Check if video opened successfully\n",
    "        if not cap.isOpened():\n",
    "            print(\"Error: Video file not found or cannot be opened.\")\n",
    "            return\n",
    "\n",
    "        annotator = Annotator(im0, line_width=2)\n",
    "        model1 = YOLO('runs/detect/train3/weights/best.pt', task='detect', verbose=False)\n",
    "        model2 = YOLO(\"yolov8n.pt\")\n",
    "        \n",
    "        results2 = model2.track(im0, persist=True, classes=[0])\n",
    "        results1 = model1(im0,show=False,conf=0.4,save=False)\n",
    "    \n",
    "        boxes1 = results1[0].boxes.xyxy.cpu()\n",
    "        \n",
    "        boxes2 = results2[0].boxes.xyxy.cpu()\n",
    "        print(boxes1)\n",
    "        \n",
    "        center_point = ((int(boxes1[0][0].item()+boxes1[0][2].item()/2)), int(boxes1[0][1].item()))\n",
    "        center_point_2 = ((int(boxes1[0][0].item()+boxes1[0][2].item()/2)), int(boxes1[0][3].item()))  # New center point (adjust coordinates as needed\n",
    "        print(center_point)\n",
    "        print(center_point_2)\n",
    "        boxes = np.concatenate((boxes1, boxes2), axis=0)\n",
    "\n",
    "        if results1[0].boxes.id is not None:\n",
    "            track_ids = results1[0].boxes.id.int().cpu().tolist()\n",
    "        if results2[0].boxes.id is not None:\n",
    "            track_ids = results2[0].boxes.id.int().cpu().tolist()\n",
    "\n",
    "            for box, track_id in zip(boxes, track_ids):\n",
    "                annotator.box_label(box, label=str(track_id), color=bbox_clr)\n",
    "                print(str(track_id))\n",
    "                if(box in boxes1.cpu().numpy()):\n",
    "                    continue\n",
    "                \n",
    "                annotator.visioneye(box, center_point)\n",
    "                annotator.visioneye(box, center_point_2)\n",
    "\n",
    "                x1, y1 = int((box[0] + box[2]) // 2), int((box[1] + box[3]) // 2)    # Bounding box centroid\n",
    "                \n",
    "                \n",
    "                if track_id in prev_coordinates:\n",
    "                    distance = math.sqrt(math.fabs(x1 - center_point[0])**2 + math.fabs(y1 - center_point[1])**2) / pixel_per_meter\n",
    "                    distance_2 = math.sqrt(math.fabs(x1 - center_point_2[0])**2 + math.fabs(y1 - center_point_2[1])**2) / pixel_per_meter\n",
    "                    \n",
    "                    # Check if the object moved away from one or both vision eyes\n",
    "                    moved_from_eye1 = distance > prev_coordinates[track_id][0]\n",
    "                    moved_from_eye2 = distance_2 > prev_coordinates[track_id][1]\n",
    "                    \n",
    "                    # direction(moved_from_eye1,moved_from_eye2)\n",
    "                    if distance <= 1 : # Moving in radius of 1 vision eye.\n",
    "                        light_state = 'yellow'\n",
    "                    elif distance_2 <= 1 : # Moving in radius of 2 vision eye.\n",
    "                        light_state = 'yellow'\n",
    "                    # elif distance_2 <= 1 : # Moving out of radius of 1 vision eye.\n",
    "                    #     light_state = 'yellow'\n",
    "                    # elif distance_2 <= 1 and not moved_from_eye1 and moved_from_eye2: # Moving out of radius of 2 vision eye.\n",
    "                        # light_state = 'yellow'\n",
    "                    elif not moved_from_eye1 and moved_from_eye2: # Moving towards 1 vision eye.\n",
    "                        light_state = 'red'\n",
    "                    elif moved_from_eye1 and not moved_from_eye2: # Moving towards 2 vision eye.\n",
    "                        light_state = 'red'\n",
    "                    else:\n",
    "                        light_state = 'green'\n",
    "                \n",
    "                # Update previous coordinates\n",
    "                prev_coordinates[track_id] = (distance, distance_2)\n",
    "\n",
    "                text_size, _ = cv2.getTextSize(f\"Distance: {distance:.2f} m\", cv2.FONT_HERSHEY_SIMPLEX,1.2, 3)\n",
    "                cv2.rectangle(im0, (x1, y1 - text_size[1] - 10),(x1 + text_size[0] + 10, y1), txt_background, -1)\n",
    "                cv2.putText(im0, f\"Distance: {distance:.2f} m\",(x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 1.2,txt_color, 3)\n",
    "                \n",
    "                text_size, _ = cv2.getTextSize(f\"Distance: {distance_2:.2f} m\", cv2.FONT_HERSHEY_SIMPLEX,1.2, 3)\n",
    "                cv2.rectangle(im0, (x1+60, y1+60 - text_size[1] - 10),(x1+60 + text_size[0] + 10, y1+60), txt_background_2, -1)\n",
    "                cv2.putText(im0, f\"Distance: {distance_2:.2f} m\",(x1+60, y1+60 - 5), cv2.FONT_HERSHEY_SIMPLEX, 1.2,txt_color_2, 3)\n",
    "                \n",
    "                # Create empty canvas\n",
    "                canvas = np.full((height, width, 3), (255, 255, 255), dtype=np.uint8)\n",
    "                border_color = (0, 0, 0)\n",
    "                \n",
    "                # light(light_state,distance,distance_2,moved_from_eye1,moved_from_eye2)\n",
    "                \n",
    "        # Create empty canvas\n",
    "        canvas = np.full((height, width, 3), (255, 255, 255), dtype=np.uint8)\n",
    "        border_color = (0, 0, 0)\n",
    "\n",
    "        # Draw border\n",
    "        border_thickness = 1\n",
    "        cv2.rectangle(canvas, (0, 0), (width, height-1), border_color, border_thickness)\n",
    "\n",
    "        # im0 = imutils.resize(im0, width=800)  # Resize the image\n",
    "        im0 = cv2.resize(im0, (600, 500))\n",
    "        # height, width = im0.shape[:2]  # Get image height and width\n",
    "        canvas = np.full((height, width, 3), (255, 255, 255), dtype=np.uint8)  # Create canvas with image dimensions\n",
    "        border_color = (0, 0, 0)\n",
    "        \n",
    "        # Draw border\n",
    "        border_thickness = 1\n",
    "        cv2.rectangle(canvas, (0, 0), (width+100, height-1), border_color, border_thickness)\n",
    "        # Place video frame on the left\n",
    "        canvas[:500, :600] = im0\n",
    "        draw_traffic_light(canvas, light_state)\n",
    "\n",
    "        # Draw digital timer at the bottom\n",
    "        elapsed_time = int(time.time() - start_time)\n",
    "        draw_timer(canvas, elapsed_time)\n",
    "\n",
    "        # Show canvas\n",
    "        cv2.imshow(\"Okay\",canvas)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    out.release()\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 3 persons, 666.0ms\n",
      "Speed: 22.0ms preprocess, 666.0ms inference, 5783.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 -, 1728.5ms\n",
      "Speed: 29.1ms preprocess, 1728.5ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "tensor([[   3.3398,  685.1064, 1054.6182, 1064.6210]])\n",
      "(530, 685)\n",
      "(530, 1064)\n",
      "1\n",
      "2\n",
      "3\n",
      "\n",
      "0: 640x640 4 persons, 363.0ms\n",
      "Speed: 15.0ms preprocess, 363.0ms inference, 6.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 -, 1751.0ms\n",
      "Speed: 23.9ms preprocess, 1751.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "tensor([[   3.5794,  683.7403, 1054.2954, 1065.0560]])\n",
      "(530, 683)\n",
      "(530, 1065)\n",
      "1\n",
      "2\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
